{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Author: Tamirlan Seidakhmetov\n",
        "\n",
        "This colab is built as a part of the CS224W Final Project. The Final Project draft blogpost could be found [here](https://medium.com/@tseidakhmetov/graph-neural-network-based-movie-recommender-system-5876b9686df3)\n",
        "\n",
        "This colab will walk us through building a Movie Recommender System using the Graph Neural Network approach. Specifically, we will employ an [Inductive Graph Based Matrix Completion](https://openreview.net/pdf?id=ByxxgCEYDS) (IGMC) framework introduced at the ICLR 2020 conference. The code structure has been inspired/adapted from the paper's official [Github page](https://github.com/muhanzhang/IGMC.git).\n",
        "\n",
        "First, we start by installing the necessary packages."
      ],
      "metadata": {
        "id": "5qMNfK27kbyo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-yaCtfGSx79"
      },
      "source": [
        "%%capture\n",
        "!pip install torch-geometric==2.0.1\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we clone the public Github code that will help us download the data and do some preprocessing. We move the required files outside of the cloned folder to use them later"
      ],
      "metadata": {
        "id": "JgRPTJ0q9LqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b latest https://github.com/muhanzhang/IGMC.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Uuh4Sp-jkiD",
        "outputId": "77c3471c-7946-41e1-8a0f-88ff2538a41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'IGMC' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "files_to_move = ['util_functions.py', 'data_utils.py', 'preprocessing.py']\n",
        "for f in files_to_move:\n",
        "  if not os.path.exists(f):\n",
        "    shutil.move(os.path.join('IGMC', f), f)"
      ],
      "metadata": {
        "id": "6Ge1Vqzoj-xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, load the required torch and torch_geometric libraries. In addition, we load a few useful functions from the GitHub code that we've cloned above.\n",
        "\n"
      ],
      "metadata": {
        "id": "7txdJHMBG42d"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnwLa71nSiY1"
      },
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.nn import RGCNConv\n",
        "from torch_geometric.utils import dropout_adj\n",
        "from util_functions import *\n",
        "from data_utils import *\n",
        "from preprocessing import *\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the variables: learning rate, epochs, and batch size.\n",
        "LR_DECAY_STEP and LR_DECAY_VALUE help decrease the learning rate over time to improve the training process/\n",
        "In the original experiment, I've trained the model for 80 epochs, here replacing it by 5 for the code to run fast."
      ],
      "metadata": {
        "id": "l9kJjP0YLfvz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bYTIuSwUobd"
      },
      "source": [
        "# Arguments\n",
        "EPOCHS=2\n",
        "BATCH_SIZE=50\n",
        "LR=1e-3\n",
        "LR_DECAY_STEP = 20\n",
        "LR_DECAY_VALUE = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a seed, it will help with the reporoducibility of the results. In addition, define a device (cpu vs. cuda)"
      ],
      "metadata": {
        "id": "Sui3tE2jL0C2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdyLvfBPU_Vs",
        "outputId": "81c29b0a-42a3-4515-ca62-4860afdfdd82"
      },
      "source": [
        "torch.manual_seed(123)\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(123)\n",
        "    torch.cuda.synchronize()\n",
        "    device = torch.device('cuda')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the code from the GitHub to download and clean the MovieLens 100k dataset"
      ],
      "metadata": {
        "id": "rSMENitdMIAa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln9Rsz2mUtEw",
        "outputId": "627d6124-ed66-4ea3-879b-961aaacac6e2"
      },
      "source": [
        "(u_features, v_features, adj_train, train_labels, train_u_indices, train_v_indices, val_labels,\n",
        "val_u_indices, val_v_indices, test_labels, test_u_indices, test_v_indices, class_values\n",
        ") = load_official_trainvaltest_split('ml_100k', testing=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User features shape: (943, 23)\n",
            "Item features shape: (1682, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we use the predefined code from the Github to extract an enclosing subgraph for a given graph G. This step was described in details in the section 2 of the Medium Blogpost."
      ],
      "metadata": {
        "id": "M23jVjpfMbuv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXPLokDtSpZG",
        "outputId": "ebe77596-3a26-4d94-cafd-b86d5e76eaba"
      },
      "source": [
        "train_dataset = eval('MyDynamicDataset')(root='data/ml_100k/testmode/train', A=adj_train,\n",
        "    links=(train_u_indices, train_v_indices), labels=train_labels, h=1, sample_ratio=1.0,\n",
        "    max_nodes_per_hop=200, u_features=None, v_features=None, class_values=class_values)\n",
        "test_dataset = eval('MyDataset')(root='data/ml_100k/testmode/test', A=adj_train,\n",
        "    links=(test_u_indices, test_v_indices), labels=test_labels, h=1, sample_ratio=1.0,\n",
        "    max_nodes_per_hop=200, u_features=None, v_features=None, class_values=class_values)\n",
        "\n",
        "len(train_dataset), len(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we define the IGMC model architecture. It consists of several steps:\n",
        "\n",
        "1.  Optionally add the graph-level dropout layer. It randomly drops edges from the graph, helping avoid overfitting and making the model more robust.\n",
        "2. The message passing layer that extracts node information for each node in the subgraph. As proposed in the table, we implement it using R-GCN layer to handle different edge types.\n",
        "3. Pass it through the tanh non-linearity\n",
        "4. We stack the outputs of step 2 and 3 at each message passing layer\n",
        "5. Concatenate the node representations at each layer in the final node representation h.\n",
        "6. Pull the graph level features g by concatenating target user and item representations.\n",
        "7. Add a linear layer, ReLU non-linearity, Dropout to avoid overfitting, and final linear layer\n",
        "\n",
        "All the model parameters were chosen following the IGMC paper.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wmm2ZA8LNt7m"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6QN6-_xUzlJ"
      },
      "source": [
        "class IGMC(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IGMC, self).__init__()\n",
        "        self.rel_graph_convs = torch.nn.ModuleList()\n",
        "        self.rel_graph_convs.append(RGCNConv(in_channels=4, out_channels=32, num_relations=5, num_bases=4))\n",
        "        self.rel_graph_convs.append(RGCNConv(in_channels=32, out_channels=32, num_relations=5, num_bases=4))\n",
        "        self.rel_graph_convs.append(RGCNConv(in_channels=32, out_channels=32, num_relations=5, num_bases=4))\n",
        "        self.rel_graph_convs.append(RGCNConv(in_channels=32, out_channels=32, num_relations=5, num_bases=4))\n",
        "        self.linear_layer1 = Linear(256, 128)\n",
        "        self.linear_layer2 = Linear(128, 1)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.linear_layer1.reset_parameters()\n",
        "        self.linear_layer2.reset_parameters()\n",
        "        for i in self.rel_graph_convs:\n",
        "            i.reset_parameters()\n",
        "\n",
        "    def forward(self, data):\n",
        "        num_nodes = len(data.x)\n",
        "        edge_index_dr, edge_type_dr = dropout_adj(data.edge_index, data.edge_type, p=0.2, num_nodes=num_nodes, training=self.training)\n",
        "\n",
        "        out = data.x\n",
        "        h = []\n",
        "        for conv in self.rel_graph_convs:\n",
        "            out = conv(out, edge_index_dr, edge_type_dr)\n",
        "            out = torch.tanh(out)\n",
        "            h.append(out)\n",
        "        h = torch.cat(h, 1)\n",
        "        h = [h[data.x[:, 0] == True], h[data.x[:, 1] == True]]\n",
        "        g = torch.cat(h, 1)\n",
        "        out = self.linear_layer1(g)\n",
        "        out = F.relu(out)\n",
        "        out = F.dropout(out, p=0.5, training=self.training)\n",
        "        out = self.linear_layer2(out)\n",
        "        out = out[:,0]\n",
        "        return out\n",
        "\n",
        "model = IGMC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a DataLoader to prepare train and test data batches"
      ],
      "metadata": {
        "id": "yjVO8ZTiR1pM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zfc33AIU3Yr",
        "outputId": "7fbf2963-fcdb-490f-d551-c0c7507b8aa2"
      },
      "source": [
        "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, BATCH_SIZE, shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure model is using GPU. Reset the model parameters and define the optimizer. We are using Adam optimizer here"
      ],
      "metadata": {
        "id": "TgIzk0jhSIn-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2xlebsTU6AS"
      },
      "source": [
        "model.to(device)\n",
        "model.reset_parameters()\n",
        "optimizer = Adam(model.parameters(), lr=LR, weight_decay=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model for number of epochs defined at the beginning.\n",
        "At each epoch we predict the labels for the batch, find the training MSE loss, do the backpropagation step and update the learnable parameters. Print the training loss at each epoch.\n",
        "\n",
        "After each LR_DECAY_STEP we decrease the learning rate by a factor of LR_DECAY_VALUE."
      ],
      "metadata": {
        "id": "3HIJ1i3dSR7F"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fxVBybWU7cU",
        "outputId": "7a3bf1bb-a80c-4170-e767-3c3cd431cf1a"
      },
      "source": [
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    train_loss_all = 0\n",
        "    for train_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        train_batch = train_batch.to(device)\n",
        "        y_pred = model(train_batch)\n",
        "        y_true = train_batch.y\n",
        "        train_loss = F.mse_loss(y_pred, y_true)\n",
        "        train_loss.backward()\n",
        "        train_loss_all += BATCH_SIZE * float(train_loss)\n",
        "        optimizer.step()\n",
        "        torch.cuda.empty_cache()\n",
        "    train_loss_all = train_loss_all / len(train_loader.dataset)\n",
        "\n",
        "    print('epoch', epoch,'; train loss', train_loss_all)\n",
        "\n",
        "    if epoch % LR_DECAY_STEP == 0:\n",
        "      for param_group in optimizer.param_groups:\n",
        "          param_group['lr'] = param_group['lr'] / LR_DECAY_VALUE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 ; train loss 1.3040544513612986\n",
            "epoch 2 ; train loss 1.0995262514427304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assess the performance of the model using the test set by predicting the labels and finding a MSE loss"
      ],
      "metadata": {
        "id": "RTIjyHN-S061"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPFRkqadVH5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b079f76a-9b10-497e-b595-e3a1f1eaec89"
      },
      "source": [
        "model.eval()\n",
        "test_loss = 0\n",
        "for test_batch in test_loader:\n",
        "    test_batch = test_batch.to(device)\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(test_batch)\n",
        "    y_true = test_batch.y\n",
        "    test_loss += F.mse_loss(y_pred, y_true, reduction='sum')\n",
        "    # torch.cuda.empty_cache()\n",
        "mse_loss = float(test_loss) / len(test_loader.dataset)\n",
        "\n",
        "print('test MSE loss', mse_loss)\n",
        "print('test RMSE loss', math.sqrt(mse_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test MSE loss 1.0167562255859375\n",
            "test RMSE loss 1.008343307403752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zogr_qoXtcGm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}